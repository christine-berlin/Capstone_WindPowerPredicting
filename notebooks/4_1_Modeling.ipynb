{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Modeling\n",
    "In this notebook we train 7 models and compare the scores to our baseline model.<br>\n",
    "The  models are run an then a dataframe is created containing the scores, the best feature combinations, and \n",
    "the results from hyperparameter tuning. We store them in the variable ```results```. <br>\n",
    "Finally, we write the dataframe ```results``` for every model to \"../results/{MODEL}.csv\". \n",
    "So for each windfarm we will find a separate model, with individual features and hyperparameters.<br><br>\n",
    "In the EDA we saw that the windspeed is a very important feature. In this notebook we will iteratively check, \n",
    "what feature combinations lead to the best results.\n",
    "To find the best feature combinations We define groups of features: <br> \n",
    "  - 'all' = all features\n",
    "  - 'no_deg' = features without ('WD100', 'WD10')\n",
    "  - 'no_deg_norm' = features without ('WD100', 'WD10', 'U100NORM', 'V100NORM')\n",
    "  - 'no_comp' = features without ('U10', 'U100', 'U100NORM', 'V10', 'V100', 'V100NORM')\n",
    "  - 'no_comp_plus_100Norm' = features without('U10', 'U100', 'V10', 'V100')\n",
    "  - 'no_ten' = features without ('WD10CARD','U10', 'V10', 'WS10', 'WD10')\n",
    "  - 'no_card' = features without 'CARD' \n",
    "  - 'no_card_100Norm' = features without ('CARD','U100NORM', 'V100NORM')\n",
    "  - 'only_ws' = 'WS100' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load modules\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from modeling.functions import adjusted_RMSE, scaler_func, train_test_split_features, \\\n",
    "                               result_to_df, get_bestfeatures, log_to_mlflow, predict_func\n",
    "from modeling.features import get_feature_combinations\n",
    "from sklearn.neighbors import KNeighborsRegressor \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import LinearSVR, SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from copy import deepcopy\n",
    "# Set random seed to ensure reproducible runs\n",
    "RSEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the cleaned dataset\n",
    "data = pd.read_csv('../data/GEFCom2014Data/Wind/clean_data.csv', parse_dates=['TIMESTAMP'], index_col='TIMESTAMP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the first 75 % of the data as training/validation set and the last 25 % as a test set. In addition, get a dictionary with different feature combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data[:'2013-07-01 00:00:00']\n",
    "data_test = data['2013-07-01 01:00:00':]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiating the 7 Regressor we will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [RandomForestRegressor(), KNeighborsRegressor(), LinearRegression(), LGBMRegressor(), LinearSVR(), \n",
    "          SVR(), XGBRegressor()] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining parameter grids for every model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grids = {\n",
    "    'RandomForestRegressor' : \n",
    "     {'n_estimators' : [100,150], 'max_depth' : np.arange(15,31,5), 'min_samples_leaf' : np.arange(10,21,10)},\n",
    "\n",
    "     'LinearRegression' :\n",
    "     {'fit_intercept' : [True]}, \n",
    "     \n",
    "     'KNeighborsRegressor' :\n",
    "     {'n_neighbors' : np.arange(20,141,10), 'weights' : ['uniform','distance'], 'p' : [1,2]} , \n",
    "     \n",
    "     'LinearSVR' : \n",
    "     {'C': [0.01, 0.1, 1, 10, 100]}, \n",
    "    \n",
    "     'SVR' : \n",
    "     {'C': [0.001, 0.01, 0.1, 1, 10]}, \n",
    "     \n",
    "     'LGBMRegressor' :\n",
    "     {'n_estimators' : [50], 'num_leaves': [62]}, \n",
    "     \n",
    "     'XGBRegressor':\n",
    "     {'random_state' : [RSEED]}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Settings for modeling applied to all models: <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the scaler, MinMaxScaler, StandardScaler, or None\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# log to MLflow or not\n",
    "log = False\n",
    "\n",
    "# number of hreads or processes that are spawned in parallel\n",
    "n_jobs = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the scoring strategy to evaluate the performance of the cross-validated model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# greater_is_better:\n",
    "# Whether score_func (in this case 'adjusted_RMSE) is a score function (default), meaning high is good, or a loss function, meaning low is good. \n",
    "# In the latter case, the scorer object will sign-flip the outcome of the score_func.\n",
    "\n",
    "scoring = make_scorer(adjusted_RMSE, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the models. And writing the scores, the best feature combinations, and \n",
    "the results from hyperparameter tuning for every model to \"../results/{MODEL}.csv\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    if model.__class__.__name__ == 'RandomForestRegressor':\n",
    "        param_grid = param_grids['RandomForestRegressor']\n",
    "\n",
    "    if model.__class__.__name__ == 'XGBRegressor':\n",
    "        param_grid = param_grids['XGBRegressor']\n",
    "\n",
    "    if model.__class__.__name__ == 'LGBMRegressor':\n",
    "        param_grid = param_grids['LGBMRegressor']\n",
    "\n",
    "    if model.__class__.__name__ == 'SVR':\n",
    "        param_grid = param_grids['SVR']\n",
    "\n",
    "    if model.__class__.__name__ == 'LinearSVR':\n",
    "        param_grid = param_grids['LinearSVR']\n",
    "\n",
    "    if model.__class__.__name__ == 'KNeighborsRegressor':\n",
    "        param_grid = param_grids['KNeighborsRegressor']\n",
    "\n",
    "    if model.__class__.__name__ == 'LinearRegression':\n",
    "        param_grid = param_grids['LinearRegression']\n",
    "    \n",
    "    # dataframe to store the best hyperparamaters, scores, best feature combinations for model/windfarm\n",
    "    df_results = pd.DataFrame()\n",
    "\n",
    "    # Run the model for every feature combination     \n",
    "    for fc in get_feature_combinations().keys():\n",
    "        #print('feature combination: {}'.format(fc))\n",
    "\n",
    "        # trainscore, testscore: rmse of predicted train/test target\n",
    "        # model_dict: stores the best estimator (model with best hyperparameters)\n",
    "        # cv_score: stores the rmse of the cross validation\n",
    "        trainscore, testscore, model_dict, cv_score = {}, {}, {}, {}\n",
    "\n",
    "        mse_train = 0\n",
    "        mse_test = 0\n",
    "        \n",
    "        features = get_feature_combinations()[fc]\n",
    "\n",
    "        # Initialize DataFrame where predictions of various zones are saved.\n",
    "        y_trainpred, y_testpred = pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "        # Run the model for every Windfarm\n",
    "        for zone in data_train.ZONEID.unique():\n",
    "            # Create a train and test dataframe for each windfarm, that has the currently selected fc as features\n",
    "            X_train, X_test, y_train, y_test = train_test_split_features(data_train, data_test, zone, features)    \n",
    "             \n",
    "            # scale data if a scaler is set \n",
    "            if scaler: \n",
    "                X_train, X_test = scaler_func(X_train, X_test, scaler)\n",
    "\n",
    "            # grid search\n",
    "            cv = GridSearchCV(model, param_grid=param_grid,\n",
    "                                  scoring=scoring, refit=True,\n",
    "                                  n_jobs=n_jobs, verbose=2)\n",
    "\n",
    "            # train the model\n",
    "            cv.fit(X_train, y_train)\n",
    "\n",
    "            cv_score[zone] = np.abs(cv.best_score_)\n",
    "            model = cv.best_estimator_    \n",
    "            model_dict[zone] = deepcopy(model)\n",
    "\n",
    "            # predict train data with the model and calculate train-score\n",
    "            y_pred = predict_func(model, X_train, y_train)\n",
    "            y_trainpred = pd.concat([y_trainpred, y_pred], axis=0)\n",
    "            trainscore['ZONE' + str(zone)] = mean_squared_error(y_pred, y_train,\n",
    "                                                            squared=False)\n",
    "\n",
    "            mse_train += np.power(trainscore['ZONE' + str(zone)], 2)\\\n",
    "                     * len(y_train)/len(data_train)\n",
    "\n",
    "            # predict test data with the model and calculate test-score\n",
    "            y_pred = predict_func(model, X_test, y_test)\n",
    "            y_testpred = pd.concat([y_testpred, y_pred], axis=0)\n",
    "            testscore['ZONE' + str(zone)] = mean_squared_error(y_pred, y_test,\n",
    "                                                           squared=False)\n",
    "\n",
    "            mse_test += np.power(testscore['ZONE' + str(zone)], 2) \\\n",
    "                    * len(y_test)/len(data_test)  # 1 / len(zones)\n",
    "\n",
    "        \n",
    "        trainscore['TOTAL'] = np.power(mse_train, 0.5)\n",
    "        testscore['TOTAL'] = np.power(mse_test, 0.5)\n",
    "\n",
    "        # track to MLFLow\n",
    "        if log:\n",
    "            for key in testscore.keys():\n",
    "                log_to_mlflow(ZONEID=key, Model=model.__class__.__name__,\n",
    "                          features=features, train_RMSE=trainscore[key],\n",
    "                          test_RMSE=testscore[key], \n",
    "                          hyperparameter=model.get_params(),\n",
    "                          model_parameters=None, scaler=scaler)\n",
    "\n",
    "            \n",
    "        df_temp = result_to_df(model_dict, testscore,\n",
    "                                     trainscore, cv_score, fc)\n",
    "        df_results = pd.concat([df_results, df_temp], axis=0)\n",
    "\n",
    "    df_results = get_bestfeatures(df_results)       \n",
    "\n",
    "    # remove file before new file is created\n",
    "    if os.path.isfile(f'../results/{df_results.MODEL.iloc[1]}.csv'):\n",
    "        os.remove(f'../results/{df_results.MODEL.iloc[1]}.csv')\n",
    "\n",
    "    # save results in csv file\n",
    "    df_results.to_csv(f'../results/{df_results.MODEL.iloc[1]}.csv')    \n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results \n",
    "The Random Forest Regressor performs best in every windfarm. The feature combinations and hyperparaneters are different for each windfarm. They can be found in the file ```RandomForestRegressor.csv```. <br>\n",
    "The following plots visualize the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot validation-RMSE and test-RMSE by model for predictions aggregated over all wind farms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define models to plot\n",
    "models = ['Baseline','LinearRegression', 'KNeighborsRegressor', 'RandomForestRegressor','LinearSVR', 'SVR', 'LGBMRegressor', 'XGBRegressor']\n",
    "\n",
    "## collect scores in the dataframe \"scores\"\n",
    "scores= pd.DataFrame(index = models, columns = ['TESTSCORE','VALSCORE'])\n",
    "\n",
    "for model in models:\n",
    "\n",
    "    df = pd.read_csv(f'../results/{model}.csv', index_col='ZONE')\n",
    "\n",
    "    if model == 'Baseline':\n",
    "        scores.loc[model]['VALSCORE'] = df.loc['TOTAL'].TRAINSCORE\n",
    "        scores.loc[model]['TESTSCORE'] = df.loc['TOTAL'].TESTSCORE\n",
    "    else:\n",
    "        scores.loc[model]['VALSCORE'] = np.sqrt(np.mean(df.CV**2))\n",
    "        scores.loc[model]['TESTSCORE'] = np.sqrt(np.mean(df.TESTSCORE**2))\n",
    "\n",
    "scores.index.set_names('MODEL', inplace=True)\n",
    "scores.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot for validation and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scoretype in ['VALSCORE', 'TESTSCORE']: \n",
    "\n",
    "    scores = scores.sort_values(by = scoretype, ascending = False, ignore_index = True)\n",
    "\n",
    "    fontsize=8\n",
    "    palette = ['blue'] + 6 * ['gray'] + ['red']\n",
    "\n",
    "    fig, ax = plt.subplots(dpi=100, figsize=(6,3))\n",
    "    bp = sns.barplot(data = scores, x = 'MODEL', y = scoretype, ax=ax, dodge=False, palette = palette)\n",
    "    ax.set_xticklabels(labels=ax.get_xticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
    "    ax.set(xlabel=None)\n",
    "    ax.set_ylabel('RMSE [-]', fontsize=fontsize)\n",
    "    ax.set_ylim([.0,.35]);\n",
    "    ax.yaxis.grid()\n",
    "    ax.tick_params(axis = 'both', labelsize = fontsize);\n",
    "\n",
    "    if scoretype == 'VALSCORE':\n",
    "        for index, row in scores.iterrows():\n",
    "                bp.text(row.name, row.VALSCORE + row.VALSCORE/100, '{:.3f}'.format(row.VALSCORE), ha='center', fontsize=fontsize)\n",
    "        fig.savefig('../images/VAL_RMSE-By-Models_Aggregated.png')\n",
    "\n",
    "    elif scoretype == 'TESTSCORE':\n",
    "        for index, row in scores.iterrows():\n",
    "            bp.text(row.name, row.TESTSCORE + row.TESTSCORE/100, '{:.3f}'.format(row.TESTSCORE), ha='center', fontsize=fontsize)\n",
    "        fig.savefig('../images/TEST_RMSE-By-Models_Aggregated.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot validation-RMSE and test-RMSE by wind farm for different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.DataFrame(columns = ['ZONE', 'MODEL', 'VALSCORE', 'TESTSCORE'])\n",
    "scores.set_index('ZONE', inplace=True)\n",
    "\n",
    "models = ['LinearRegression', 'KNeighborsRegressor', 'RandomForestRegressor','LinearSVR', 'SVR', 'LGBMRegressor', 'XGBRegressor']\n",
    "fontsize = 8\n",
    "\n",
    "for model in models:\n",
    "    df = pd.read_csv(f'../results/{model}.csv', index_col='ZONE')\n",
    "    df = df[['CV', 'TESTSCORE', 'MODEL']]\n",
    "    df.rename(columns={'CV':'VALSCORE'}, inplace=True)\n",
    "    scores = scores.append(df) \n",
    "\n",
    "scores = scores.loc[scores.index != 'TOTAL']\n",
    "ranges = scores[scores.MODEL != 'RandomForestRegressor']\n",
    "scores = scores[scores.MODEL == 'RandomForestRegressor'][['VALSCORE', 'TESTSCORE']]\n",
    "\n",
    "for scoretype in ['VAL', 'TEST']:\n",
    "\n",
    "    scores['MINVAL'] = [ranges.loc[zone][scoretype + 'SCORE'].min() for zone in ranges.index.unique()]\n",
    "    scores['MAXVAL'] = [ranges.loc[zone][scoretype + 'SCORE'].max() for zone in ranges.index.unique()]\n",
    "\n",
    "    ## plot\n",
    "    fig, ax = plt.subplots(dpi=100, figsize=(6,3))\n",
    "    ax.plot(scores.index.unique(), scores[scoretype + 'SCORE'], color='r', linestyle='--', marker='.', markersize=5, linewidth=.7)\n",
    "    ax.fill_between(scores.index.unique(), scores['MINVAL'], scores['MAXVAL'], color = 'gray', alpha=.5, edgecolor=None);\n",
    "    ax.set_xlabel('wind farm',fontsize=fontsize)\n",
    "    ax.set_ylabel('RMSE [-]', fontsize=fontsize)\n",
    "    ax.grid(linewidth=.3)\n",
    "    ax.legend(['RandomForestRegressor','range over all models without RandomForestRegressor'], fontsize=fontsize - 2, loc = 'upper left')\n",
    "    ax.set_xticklabels([zone[-1] if len(zone) == 5 else zone[-2:] for zone in scores.index]);\n",
    "    ax.set_xticklabels(range(1,11));\n",
    "\n",
    "    fig.savefig('{}{}{}'.format('../images/',scoretype,'_RMSE-By-Windfarms.png'))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f2f7753f64e9a5ea18202ac159afad03a9e7ffdb6bd0b7a7c7ce79153287d031"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
